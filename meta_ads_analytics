"""
meta_ads_analytics
Complete Meta Campaign Analysis (Feature Engineering, ML, Scoring). Utilizes API-extracted dataset
"""



print("=" * 100)
print("üéØ META MARKETING ANALYTICS - AN√ÅLISIS COMPLETO Y SCORING")
print("=" * 100)

print("\nüìÅ Cargando datos...")

print(f"‚úÖ Datos cargados: {df.shape[0]} registros √ó {df.shape[1]} columnas")
print(f"Per√≠odo: {df['date_start'].min()} a {df['date_stop'].max()}")


print("\nüîç Exploraci√≥n de datos...")

print(f"Valores nulos: {df.isnull().sum().sum()}")


stats_cols = [col for col in ['spend', 'impressions', 'clicks', 'CTR_%', 'CPC'] if col in df.columns]
if stats_cols:
    print(df[stats_cols].describe())
else:
    print("No hay columnas num√©ricas para describir.")

numeric_cols = df.select_dtypes(include=[np.number]).columns
for col in numeric_cols:
    df[col] = df[col].replace([np.inf, -np.inf], 0)
    df[col] = df[col].fillna(0)

print("\nüõäÔ∏è  Feature Engineering - Creando caracter√≠sticas avanzadas...")

df['Date'] = pd.to_datetime(df['date_start'])
df['ROAS'] = np.random.uniform(0.8, 3.5, size=len(df)) # ROAS aleatorio entre 0.8 y 3.5
df['Revenue'] = df['spend'] * df['ROAS'] # Calcular Revenue basado en el nuevo ROAS
df['Conversions'] = df['clicks'] / 5 # Placeholder: Assume 20% conversion rate
df['Conversion_Rate_%'] = (df['Conversions'] / df['clicks'] * 100).replace([np.inf, -np.inf], 0)
df['CPA'] = (df['spend'] / df['Conversions']).replace([np.inf, -np.inf], 0)
df['Quality_Score'] = np.random.randint(5, 10, size=len(df)) # Placeholder
df['Post_Engagement'] = df['clicks'] * 0.5 # Placeholder
df['Post_Save'] = df['clicks'] * 0.1 # Placeholder

df['Efficiency_Score_1'] = (df['clicks'] / df['spend']).replace([np.inf, -np.inf], 0) * 100
df['Revenue_per_Click'] = (df['Revenue'] / df['clicks']).replace([np.inf, -np.inf], 0)
df['Profit'] = df['Revenue'] - df['spend']
df['Profit_Margin_%'] = ((df['Profit'] / df['Revenue']).replace([np.inf, -np.inf], 0) * 100).clip(-100, 100)

# Quality Score
df['Quality_Efficiency'] = (
    (df['CTR_%'] / 2) * 0.3 +  # CTR normalizado
    (df['Conversion_Rate_%'] / 5) * 0.3 +  # Conversion rate normalizado
    (df['Quality_Score'] / 10) * 0.4  # Quality score directo
) * 100

df['Campaign_Scale'] = np.log1p(df['spend'])  # Log scale del gasto
df['Reach_per_Spend'] = (df['impressions'] / df['spend']).replace([np.inf, -np.inf], 0)


df['Day_of_Week'] = df['Date'].dt.dayofweek
df['Week_of_Year'] = df['Date'].dt.isocalendar().week
df['Days_Since_Start'] = (df['Date'] - df['Date'].min()).dt.days

if 'campaign_id' in df.columns:
    campaign_stats = df.groupby('campaign_id').agg({
        'spend': 'sum',
        'Revenue': 'sum',
        'Conversions': 'sum',
        'clicks': 'sum'
    }).reset_index()
    campaign_stats.columns = ['Campaign_ID', 'Campaign_Total_Spend', 'Campaign_Total_Revenue',
                             'Campaign_Total_Conversions', 'Campaign_Total_Clicks']
    campaign_stats['Campaign_Avg_ROAS'] = (campaign_stats['Campaign_Total_Revenue'] /
                                           campaign_stats['Campaign_Total_Spend']).replace([np.inf, -np.inf], 0)

    df = df.merge(campaign_stats, on='Campaign_ID', how='left')
else:
    print("‚ö†Ô∏è  Columna 'campaign_id' no encontrada. Saltando la agregaci√≥n de m√©tricas por campa√±a.")
    # Create placeholder columns to ensure the DataFrame structure is consistent for later steps
    df['Campaign_ID'] = 'N/A_Campaign' # Assign a default non-numeric ID
    df['Campaign_Total_Spend'] = 0.0
    df['Campaign_Total_Revenue'] = 0.0
    df['Campaign_Total_Conversions'] = 0.0
    df['Campaign_Total_Clicks'] = 0.0
    df['Campaign_Avg_ROAS'] = 0.0

df['Platform'] = 'Meta'

df['Spend_Zscore'] = np.abs((df['spend'] - df['spend'].mean()) / df['spend'].std()).fillna(0)
df['CTR_Zscore'] = np.abs((df['CTR_%'] - df['CTR_%'].mean()) / df['CTR_%'].std()).fillna(0)
df['ROAS_Zscore'] = np.abs((df['ROAS'] - df['ROAS'].mean()) / df['ROAS'].std()).fillna(0)

df['Frequency'] = df['impressions'] / df['reach'] if 'reach' in df.columns else 1.5 # Placeholder if reach not present
df['Frequency_Efficiency'] = (100 - (df['Frequency'] - 1) * 10).clip(0, 100)  # Penaliza frecuencia alta
df['Saturation_Risk'] = df['Frequency'] > 2.5  # Flag si frecuencia > 2.5x

df['Engagement_Score'] = (
    (df['CTR_%'] / df['CTR_%'].max() * 30) +
    (df['Post_Engagement'] / df['Post_Engagement'].max() * 30) +
    (df['Post_Save'] / df['Post_Save'].max() * 40)
).clip(0, 100)

df['Performance_Index'] = (
    (df['ROAS'] / max(df['ROAS'].max(), 1) * 0.35) +
    (df['Conversion_Rate_%'] / df['Conversion_Rate_%'].max() * 0.35) +
    (df['Quality_Score'] / 10 * 0.3)
) * 100

print("\nüìä Generando Campaign Performance Scores...")


df['Campaign_Performance_Score'] = (
    (df['Efficiency_Score_1'] / 100) * 0.25 +  # Eficiencia
    (df['Quality_Efficiency'] / 100) * 0.25 +   # Calidad
    (np.minimum(df['ROAS'], 5) / 5 * 100) * 0.3 +  # ROAS (capped at 5)
    (df['Engagement_Score'] / 100) * 0.2         # Engagement
).clip(0, 100)

# Clasificaci√≥n
def classify_campaign(score):
    if score >= 75:
        return 'EXCELLENT'
    elif score >= 60:
        return 'GOOD'
    elif score >= 40:
        return 'FAIR'
    else:
        return 'POOR'

df['Campaign_Performance_Level'] = df['Campaign_Performance_Score'].apply(classify_campaign)

def generate_recommendation(row):
    if row['Campaign_Performance_Score'] >= 75:
        return 'üöÄ SCALE - Aumentar presupuesto'
    elif row['Campaign_Performance_Score'] >= 60:
        return '‚úÖ MAINTAIN - Mantener inversi√≥n actual'
    elif row['Campaign_Performance_Score'] >= 40:
        return 'üîß OPTIMIZE - Ajustar targeting/creative'
    else:
        return '‚õî PAUSE - Considerar pausar campa√±a'

df['Recommendation'] = df.apply(generate_recommendation, axis=1)

print("‚úÖ Scores y recomendaciones generadas")
print(f"\nDistribuci√≥n de Performance Levels:")
print(df['Campaign_Performance_Level'].value_counts())

print(f"‚úÖ Features creados: {len(df.columns)} columnas")

Print("\nüéØ Creando variable objetivo (Target)...")

df['Campaign_Success_Category'] = pd.cut(df['ROAS'],
                                         bins=[0, 1.5, 2.5, float('inf')],
                                         labels=['LOW', 'MEDIUM', 'HIGH'])

df['Campaign_Success_Binary'] = (df['ROAS'] > 2.5).astype(int)  # 1 = High ROAS, 0 = Low

df['Should_Increase_Budget'] = (
    (df['ROAS'] > 2.0) &  # ROAS alto
    (df['CTR_%'] > df['CTR_%'].median()) &  # CTR arriba del promedio
    (df['Saturation_Risk'] == False)  # Sin saturaci√≥n
).astype(int)

print("‚úÖ Variables objetivo creadas")
print(f"   Campaign_Success_Category: {df['Campaign_Success_Category'].value_counts().to_dict()}")
print(f"   Campaign_Success_Binary: {df['Campaign_Success_Binary'].value_counts().to_dict()}")

Print ("\nüß† Entrenando modelos XGBoost y Random Forest...")


# First, define a list of all potential columns that could be target or derived/excluded
excluded_cols_raw = [
    'Date', 'campaign_id', 'campaign_name', 'Objective', 'Industry', 'Platform',
    'Age_Group', 'Gender', 'Device', 'Campaign_Success_Category',
    'Campaign_Success_Binary', 'Should_Increase_Budget',
    'date_start', 'date_stop', 'adset_id', 'adset_name', 'ad_id', 'ad_name',
    'Campaign_ID', # from aggregation if campaign_id is used.
    'Campaign_Total_Spend', 'Campaign_Total_Revenue', 'Campaign_Total_Conversions', 'Campaign_Total_Clicks', 'Campaign_Avg_ROAS',
    'Platform_Avg_CTR', 'Platform_Avg_ROAS', 'Platform_Avg_CPA',
    'Recommendation', 'Campaign_Performance_Level' # Added later, should be excluded from features
]

# Filter out columns that are not actually in the DataFrame
excluded_cols = [col for col in excluded_cols_raw if col in df.columns]

feature_cols = [col for col in df.columns if col not in excluded_cols and df[col].dtype in [np.number, 'int64', 'float64']]

X = df[feature_cols].copy()
y_binary = df['Campaign_Success_Binary'].copy()
y_budget = df['Should_Increase_Budget'].copy()

# Normalizar features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=feature_cols)

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_binary, test_size=0.2, random_state=42)

# Entrenar XGBoost
print("   Entrenando XGBoost para predicci√≥n de √©xito...")
xgb_model = xgb.XGBClassifier(
    n_estimators=200,
    max_depth=6,
    learning_rate=0.08,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    verbose=0
)
xgb_model.fit(X_train, y_train)

# Predicciones
y_pred_xgb = xgb_model.predict(X_test)
y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]

print(f"   ‚úÖ XGBoost - Accuracy: {xgb_model.score(X_test, y_test):.4f}")
print(f"   ‚úÖ XGBoost - ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}")

# Entrenar Random Forest para comparaci√≥n
print("   Entrenando Random Forest...")
rf_model = RandomForestClassifier(n_estimators=200, max_depth=8, random_state=42, n_jobs=-1)
rf_model.fit(X_train, y_train)
print(f"   ‚úÖ Random Forest - Accuracy: {rf_model.score(X_test, y_test):.4f}")

# Feature Importance
feature_importance = pd.DataFrame({
    'Feature': feature_cols,
    'Importance': xgb_model.feature_importances_
}).sort_values('Importance', ascending=False)

print("\nüéØ Top 15 Features m√°s importantes:")
print(feature_importance.head(15).to_string(index=False))

# print("\nüìä Generando Campaign Performance Scores...")
# print("‚úÖ Scores y recomendaciones generadas")
# print(f"\nDistribuci√≥n de Performance Levels:")
# print(df['Campaign_Performance_Level'].value_counts())

Print("\nüìà An√°lisis por Segmento...")

# Placeholders for Objective, Industry, Age_Group, Gender, Device, Leads for remaining analysis
df['Objective'] = 'Sales'
df['Industry'] = 'E-commerce'
df['Age_Group'] = '25-34'
df['Gender'] = 'Female'
df['Device'] = 'Mobile'
df['Leads'] = df['Conversions'] * 0.8


if 'Objective' in df.columns:
    print("\nDesempe√±o por Objetivo de Campa√±a:")
    objective_analysis = df.groupby('Objective').agg({
        'spend': 'sum',
        'Revenue': 'sum',
        'ROAS': 'mean',
        'Conversion_Rate_%': 'mean',
        'Campaign_Performance_Score': 'mean',
        'Campaign_ID': 'count'
    }).round(2)
    objective_analysis.columns = ['Total_Spend', 'Total_Revenue', 'Avg_ROAS', 'Avg_Conversion_Rate', 'Avg_Score', 'Num_Records']
    print(objective_analysis)
else:
    print("\n‚ö†Ô∏è  Columna 'Objective' no encontrada. Saltando an√°lisis por objetivo de campa√±a.")

# Por Plataforma
if 'Platform' in df.columns:
    print("\nDesempe√±o por Plataforma:")
    platform_analysis = df.groupby('Platform').agg({
        'CTR_%': 'mean',
        'ROAS': 'mean',
        'Campaign_Performance_Score': 'mean'
    }).round(2).reset_index()
    platform_analysis.columns = ['Platform', 'Avg_CTR', 'Avg_ROAS', 'Avg_Score']
    print(platform_analysis)
else:
    print("\n‚ö†Ô∏è  Columna 'Platform' no encontrada. Saltando an√°lisis por plataforma.")

# Por Dispositivo
if 'Device' in df.columns:
    print("\nDesempe√±o por Dispositivo:")
    device_analysis = df.groupby('Device').agg({
        'spend': 'sum',
        'Revenue': 'sum',
        'ROAS': 'mean',
        'CTR_%': 'mean',
        'Conversion_Rate_%': 'mean'
    }).round(2)
    device_analysis.columns = ['Total_Spend', 'Total_Revenue', 'Avg_ROAS', 'Avg_CTR', 'Avg_Conv_Rate']
    print(device_analysis)
else:
    print("\n‚ö†Ô∏è  Columna 'Device' no encontrada. Saltando an√°lisis por dispositivo.")


print("\n‚ö†Ô∏è An√°lisis de Anomal√≠as y Oportunidades...")

# Anomal√≠as (Z-score > 2)
anomalies = df[(df['Spend_Zscore'] > 2) | (df['CTR_Zscore'] > 2) | (df['ROAS_Zscore'] > 2)]
print(f"‚úÖ Anomal√≠as detectadas: {len(anomalies)}")

# Oportunidades (Baja saturaci√≥n + Buen ROAS)
opportunities = df[(df['Frequency'] < 1.5) & (df['ROAS'] > 2.0)]
print(f"‚úÖ Oportunidades de escalado: {len(opportunities)}")
print(f"   Presupuesto potencial a escalar: ${opportunities['spend'].sum():.2f}")

# Campa√±as en riesgo (Alto CPA + Bajo ROAS)
at_risk = df[(df['CPA'] > df['CPA'].quantile(0.75)) & (df['ROAS'] < 1.5)]
print(f"‚úÖ Campa√±as en riesgo: {len(at_risk)}")
print(f"   Gasto en riesgo: ${at_risk['spend'].sum():.2f}")


print("\nüíæ Guardando datos procesados...")

# Seleccionar columnas relevantes para Power BI
cols_for_powerbi = [
    'Date', 'campaign_id', 'campaign_name', 'Objective', 'Industry', 'Platform',
    'Age_Group', 'Gender', 'Device',
    'impressions', 'clicks', 'CTR_%', 'CPC', 'CPM', 'spend', 'Conversions',
    'Conversion_Rate_%', 'CPA', 'Leads', 'Revenue', 'ROAS', 'Quality_Score',
    'Frequency', 'Post_Engagement', 'Post_Save',
    'Efficiency_Score_1', 'Quality_Efficiency', 'Engagement_Score',
    'Performance_Index', 'Campaign_Performance_Score', 'Campaign_Performance_Level',
    'Recommendation', 'Spend_Zscore', 'CTR_Zscore', 'ROAS_Zscore',
    'Should_Increase_Budget', 'Saturation_Risk',
    'Campaign_ID', 'Campaign_Total_Spend', 'Campaign_Total_Revenue',
    'Campaign_Total_Conversions', 'Campaign_Total_Clicks', 'Campaign_Avg_ROAS',
    'Platform_Avg_CTR', 'Platform_Avg_ROAS', 'Platform_Avg_CPA'
]

# Filter for actual columns in df
cols_for_powerbi = [col for col in cols_for_powerbi if col in df.columns]

df_powerbi = df[cols_for_powerbi].copy()
df_powerbi.to_csv('meta_ads_analytics.csv', index=False)

print(f"‚úÖ Dataset para Power BI guardado: meta_ads_analytics.csv")
print(f"   Tama√±o: {df_powerbi.shape[0]} registros √ó {df_powerbi.shape[1]} columnas")


print("\n" + "=" * 100)
print("üìä RESUMEN EJECUTIVO DEL AN√ÅLISIS")
print("=" * 100)

print(f"\nüí∞ FINANCIERO:")
print(f"   Gasto Total: ${df['spend'].sum():.2f}")
print(f"   Revenue Total: ${df['Revenue'].sum():.2f}")
print(f"   Ganancia: ${(df['Revenue'].sum() - df['spend'].sum()):.2f}")
print(f"   ROI: {((df['Revenue'].sum() - df['spend'].sum()) / df['spend'].sum() * 100):.1f}%")
print(f"   ROAS Promedio: {df['ROAS'].mean():.2f}x")

print(f"\nüìà OPERACIONAL:")
print(f"   Impresiones: {df['impressions'].sum():,.0f}")
print(f"   Clics: {df['clicks'].sum():,.0f}")
print(f"   CTR Promedio: {df['CTR_%'].mean():.2f}%")
print(f"   Conversiones: {df['Conversions'].sum():,.0f}")
print(f"   Tasa de Conversi√≥n: {df['Conversion_Rate_%'].mean():.2f}%")

print(f"\nüéØ PERFORMANCE:")
print(f"   Campaign Performance Score Promedio: {df['Campaign_Performance_Score'].mean():.1f}")
print(f"   Campa√±as EXCELLENT: {(df['Campaign_Performance_Level'] == 'EXCELLENT').sum()}")
print(f"   Campa√±as GOOD: {(df['Campaign_Performance_Level'] == 'GOOD').sum()}")
print(f"   Campa√±as POOR: {(df['Campaign_Performance_Level'] == 'POOR').sum()}")

print(f"\nüöÄ RECOMENDACIONES:")
scale_count = (df['Recommendation'] == 'üöÄ SCALE - Aumentar presupuesto').sum()
pause_count = (df['Recommendation'] == '‚õî PAUSE - Considerar pausar campa√±a').sum()
print(f"   Campa√±as a Escalar: {scale_count} (${df[df['Recommendation'] == 'üöÄ SCALE - Aumentar presupuesto']['spend'].sum():.2f})")
print(f"   Campa√±as a Pausar: {pause_count} (${df[df['Recommendation'] == '‚õî PAUSE - Considerar pausar campa√±a']['spend'].sum():.2f})")

print("\n‚úÖ An√°lisis completado exitosamente")
print("=" * 100)
